#!/usr/bin/env python3
"""
NCU è‡ªåŠ¨åŒ–æ€§èƒ½åˆ†æå·¥å…·
æ”¯æŒä» ncu-rep æ–‡ä»¶ç›´æ¥å¯¼å…¥åˆ†æ

ä½¿ç”¨æ–¹æ³•:
    # åˆ†æ ncu-rep æ–‡ä»¶
    python ncu_analyzer.py --import profile.ncu-rep
    
    # åˆ†æå¹¶ä¿å­˜æŠ¥å‘Š
    python ncu_analyzer.py --import profile.ncu-rep -o analysis.md
"""

import argparse
import json
import re
import subprocess
import sys
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple
from pathlib import Path


@dataclass
class Diagnosis:
    bottleneck_type: str
    confidence: str
    reason: str
    suggestions: List[Dict] = field(default_factory=list)


class NCUAnalyzer:
    # ä¼˜åŒ–å»ºè®®æ˜ å°„
    OPTIMIZATIONS = {
        "DRAM_MEMORY_BOUND": [
            {
                "name": "Block Tiling",
                "action": "ä½¿ç”¨å…±äº«å†…å­˜ç¼“å­˜ BMÃ—BK å’Œ BKÃ—BN æ•°æ®å—ï¼Œå‡å°‘å…¨å±€å†…å­˜è®¿é—®",
                "gain": "3-5x",
                "complexity": "medium",
                "code": "__shared__ float As[BM][BK];\n__shared__ float Bs[BK][BN];"
            },
            {
                "name": "Vectorized Load",
                "action": "ä½¿ç”¨ float4 åŠ è½½å…¨å±€å†…å­˜ï¼Œå‡å°‘å†…å­˜äº‹åŠ¡æ•°é‡",
                "gain": "1.5-2x",
                "complexity": "low",
                "code": "float4 tmp = reinterpret_cast<float4*>(&A[idx])[0];"
            },
            {
                "name": "Prefetching",
                "action": "åœ¨è®¡ç®—å½“å‰å—æ—¶é¢„å–ä¸‹ä¸€å—æ•°æ®ï¼Œéšè—å†…å­˜å»¶è¿Ÿ",
                "gain": "1.2-1.5x",
                "complexity": "high"
            }
        ],
        "L1_PRESSURE_BOUND": [
            {
                "name": "Shared Memory Padding",
                "action": "åœ¨å…±äº«å†…å­˜æ•°ç»„ç¬¬äºŒç»´æ·»åŠ  +1 paddingï¼Œé¿å… bank conflict",
                "gain": "1.2-2x",
                "complexity": "low",
                "code": "__shared__ float As[BM][BK+1];  // +1 padding"
            },
            {
                "name": "Data Transpose",
                "action": "A çŸ©é˜µè½¬ç½®å­˜å‚¨ï¼Œæ”¹å–„å…±äº«å†…å­˜è®¿é—®æ¨¡å¼",
                "gain": "1.3-1.8x",
                "complexity": "medium"
            },
            {
                "name": "Fragment Caching",
                "action": "ä½¿ç”¨å¯„å­˜å™¨ç¼“å­˜é¢‘ç¹è®¿é—®çš„æ•°æ®ç‰‡æ®µ",
                "gain": "1.2-1.5x",
                "complexity": "medium"
            }
        ],
        "COMPUTE_BOUND": [
            {
                "name": "FMA Optimization",
                "action": "ä½¿ç”¨ fmaf() æ›¿ä»£ separate mul+addï¼Œæé«˜æŒ‡ä»¤åå",
                "gain": "1.1-1.3x",
                "complexity": "low",
                "code": "tmp = fmaf(a, b, tmp);  // æ›¿ä»£ tmp += a * b"
            },
            {
                "name": "Loop Unroll",
                "action": "ä½¿ç”¨ #pragma unroll å±•å¼€å¾ªç¯ï¼Œå‡å°‘æ§åˆ¶å¼€é”€",
                "gain": "1.1-1.2x",
                "complexity": "low",
                "code": "#pragma unroll"
            },
            {
                "name": "Tensor Core",
                "action": "ä½¿ç”¨ WMMA æˆ– mma.sync æŒ‡ä»¤åˆ©ç”¨ Tensor Core",
                "gain": "2-8x",
                "complexity": "high"
            }
        ],
        "LATENCY_BOUND": [
            {
                "name": "Double Buffering",
                "action": "ä½¿ç”¨åŒç¼“å†²é‡å è®¡ç®—å’Œå†…å­˜è®¿é—®",
                "gain": "1.2-1.5x",
                "complexity": "medium",
                "code": "__shared__ float As[2][BM*BK]; // ping-pong"
            },
            {
                "name": "Increase Occupancy",
                "action": "è°ƒæ•´ block size æˆ–å‡å°‘å¯„å­˜å™¨ä½¿ç”¨",
                "gain": "1.2-2x",
                "complexity": "medium"
            },
            {
                "name": "Warp Tiling",
                "action": "ç»†ç²’åº¦å¹¶è¡Œå‡å°‘åŒæ­¥å¼€é”€",
                "gain": "1.3-2x",
                "complexity": "high"
            }
        ],
        "OCCUPANCY_BOUND": [
            {
                "name": "Reduce Registers",
                "action": "ä½¿ç”¨ __launch_bounds__ æˆ– volatile å‡å°‘å¯„å­˜å™¨",
                "gain": "1.2-2x",
                "complexity": "medium",
                "code": "__launch_bounds__(256, 2)"
            },
            {
                "name": "Adjust TM/TN",
                "action": "å‡å°‘æ¯ä¸ªçº¿ç¨‹å¤„ç†å…ƒç´ æ•°ï¼Œé™ä½å¯„å­˜å™¨å‹åŠ›",
                "gain": "1.2-1.5x",
                "complexity": "low"
            },
            {
                "name": "Dynamic Shared Memory",
                "action": "ä½¿ç”¨åŠ¨æ€å…±äº«å†…å­˜åˆ†é…",
                "gain": "1.1-1.2x",
                "complexity": "low",
                "code": "extern __shared__ float shared[];"
            }
        ]
    }
    
    def __init__(self):
        self.metrics: Dict[str, float] = {}
        self.kernels: Dict[str, Dict[str, float]] = {}
        self.report_file: Optional[str] = None
        
    def extract_from_ncu_rep(self, ncu_rep: str) -> Dict[str, Dict[str, float]]:
        """ä» ncu-rep æ–‡ä»¶æå–æ‰€æœ‰ kernel çš„æŒ‡æ ‡"""
        self.report_file = ncu_rep
        
        cmd = ["ncu", "--import", ncu_rep, "--print-summary", "per-kernel"]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            if result.returncode != 0:
                print(f"Error running ncu: {result.stderr}")
                return {}
            
            self.kernels = self.parse_summary_output(result.stdout)
            return self.kernels
            
        except Exception as e:
            print(f"Error extracting from ncu-rep: {e}")
            return {}
        
    def parse_summary_output(self, output: str) -> Dict[str, Dict[str, float]]:
        """è§£æ ncu --print-summary çš„è¾“å‡º"""
        kernels = {}
        current_kernel = None
        current_section = None
        
        lines = output.split('\n')
        i = 0
        while i < len(lines):
            line = lines[i]
            stripped = line.strip()
            
            # è¯†åˆ« kernel åç§°è¡Œ
            # æ ¼å¼: mysgemm_v1(...) (64, 64, 1)x(32, 32, 1), Device 0, CC 8.9
            if stripped and not stripped.startswith('Section:') and not stripped.startswith('---') and not stripped.startswith('Metric'):
                # æ£€æŸ¥æ˜¯å¦åŒ…å« kernel ç‰¹å¾
                if '(' in stripped and 'x(' in stripped and 'Device' in stripped:
                    # æå– kernel å (åœ¨ç¬¬ä¸€ä¸ª ( ä¹‹å‰)
                    match = re.match(r'^(.+?)\s*\([^)]+\)\s*\([^)]+\)x\([^)]+\)', stripped)
                    if match:
                        current_kernel = match.group(1).strip()
                        kernels[current_kernel] = {}
                        current_section = None
                        i += 1
                        continue
            
            # è¯†åˆ« Section
            if stripped.startswith('Section:'):
                current_section = stripped.replace('Section:', '').strip()
                i += 1
                continue
            
            # è§£æè¡¨æ ¼æ•°æ®è¡Œ
            if current_kernel and current_section and stripped.startswith('|'):
                # è¡¨æ ¼æ ¼å¼: | Metric Name | Unit | Min | Max | Avg |
                parts = [p.strip() for p in stripped.split('|') if p.strip()]
                if len(parts) >= 5:
                    metric_name = parts[0]
                    try:
                        # ä½¿ç”¨ Average åˆ—
                        avg_value = float(parts[-1])
                        kernels[current_kernel][metric_name] = avg_value
                    except:
                        pass
                i += 1
                continue
            
            # è§£æå›ºå®šæ ¼å¼è¡Œ (æ ¼å¼: Metric Name    Unit    Value)
            if current_kernel and current_section:
                # å°è¯•åŒ¹é…: Name    Unit    Min    Max    Avg
                # æˆ–: Name    Unit    Value
                parts = stripped.split()
                if len(parts) >= 3:
                    # æ£€æŸ¥æœ€åå‡ ä¸ªéƒ¨åˆ†æ˜¯å¦æ˜¯æ•°å€¼
                    try:
                        # å°è¯•è§£ææ•°å€¼ (å¯èƒ½æ˜¯ Average åˆ—)
                        for j in range(len(parts) - 1, max(len(parts) - 4, 0), -1):
                            try:
                                value = float(parts[j])
                                # æ‰¾åˆ°äº†æ•°å€¼ï¼Œå‰é¢çš„å°±æ˜¯ metric name
                                # ä½†æ˜¯éœ€è¦æ’é™¤ unit
                                metric_parts = []
                                for k in range(j):
                                    if parts[k] not in ['cycle', '%', 'Ghz', 'ms', 'us', 'ns', 'byte', 'Kbyte', 'Mbyte', 'warp', 'block', 'thread', 'SM']:
                                        metric_parts.append(parts[k])
                                    else:
                                        # è¿™æ˜¯ unitï¼Œåœæ­¢
                                        break
                                
                                if metric_parts:
                                    metric_name = ' '.join(metric_parts)
                                    kernels[current_kernel][metric_name] = value
                                break
                            except:
                                continue
                    except:
                        pass
            
            i += 1
        
        return kernels
    
    def get_standardized_metrics(self, kernel_metrics: Dict[str, float]) -> Dict[str, float]:
        """å°† NCU æŒ‡æ ‡åè½¬æ¢ä¸ºæ ‡å‡†æŒ‡æ ‡å"""
        std_metrics = {}
        
        # æ˜ å°„è¡¨ (NCU åŸå§‹å -> æ ‡å‡†å)
        mapping = {
            'Compute (SM) Throughput': 'sm_throughput',
            'Memory Throughput': 'memory_throughput',
            'DRAM Throughput': 'dram_throughput',
            'L1/TEX Cache Throughput': 'l1tex_throughput',
            'L2 Cache Throughput': 'l2_throughput',
            'SM Busy': 'sm_busy',
            'Achieved Occupancy': 'occupancy',
            'Theoretical Occupancy': 'theoretical_occupancy',
            'Duration': 'duration',
            'Block Size': 'block_size',
            'Grid Size': 'grid_size',
            'Registers Per Thread': 'registers',
        }
        
        for ncu_name, std_name in mapping.items():
            if ncu_name in kernel_metrics:
                std_metrics[std_name] = kernel_metrics[ncu_name]
        
        return std_metrics
    
    def get_user_kernel(self) -> Tuple[str, Dict[str, float]]:
        """è·å–ç”¨æˆ· kernel (æ’é™¤ cuBLAS/cutlass ç­‰åº“å‡½æ•°)"""
        for name, metrics in self.kernels.items():
            # æ’é™¤å·²çŸ¥åº“å‡½æ•°
            if any(lib in name.lower() for lib in ['cublas', 'cutlass', 'cudnn']):
                continue
            # ä¼˜å…ˆé€‰æ‹©åŒ…å«å¸¸è§ kernel å‘½åæ¨¡å¼çš„
            if any(pattern in name for pattern in ['mysgemm', 'kernel', 'matmul', 'softmax']):
                return name, self.get_standardized_metrics(metrics)
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…çš„ï¼Œè¿”å›ç¬¬ä¸€ä¸ªéåº“å‡½æ•°
        for name, metrics in self.kernels.items():
            if not any(lib in name.lower() for lib in ['cublas', 'cutlass']):
                return name, self.get_standardized_metrics(metrics)
        
        # è¿”å›ç¬¬ä¸€ä¸ª
        name, metrics = next(iter(self.kernels.items()))
        return name, self.get_standardized_metrics(metrics)
    
    def diagnose(self, metrics: Dict[str, float]) -> List[Diagnosis]:
        """è‡ªåŠ¨è¯Šæ–­ç“¶é¢ˆ"""
        diagnoses = []
        
        dram = metrics.get('dram_throughput', 0)
        l1tex = metrics.get('l1tex_throughput', 0)
        sm_busy = metrics.get('sm_busy', 0)
        sm_throughput = metrics.get('sm_throughput', 0)
        memory_throughput = metrics.get('memory_throughput', 0)
        occupancy = metrics.get('occupancy', 0)
        
        # L1 Pressure Bound (æœ€å¸¸è§)
        if l1tex > 80 and dram < 30:
            diagnoses.append(Diagnosis(
                bottleneck_type="L1_PRESSURE_BOUND",
                confidence="HIGH",
                reason=f"L1/TEX Throughput ({l1tex:.1f}%) > 80%ï¼Œä½† DRAM ({dram:.1f}%) < 30%ï¼Œè¯´æ˜ L1 ç¼“å­˜å‹åŠ›è¿‡é«˜",
                suggestions=self.OPTIMIZATIONS["L1_PRESSURE_BOUND"]
            ))
        
        # DRAM Memory Bound
        if dram > 70:
            diagnoses.append(Diagnosis(
                bottleneck_type="DRAM_MEMORY_BOUND",
                confidence="HIGH",
                reason=f"DRAM Throughput ({dram:.1f}%) > 70%ï¼Œæ˜¾å­˜å¸¦å®½æˆä¸ºç“¶é¢ˆ",
                suggestions=self.OPTIMIZATIONS["DRAM_MEMORY_BOUND"]
            ))
        
        # Compute Bound (SM Throughput å’Œ Memory Throughput éƒ½å¾ˆé«˜)
        if sm_throughput > 80 and memory_throughput > 80:
            diagnoses.append(Diagnosis(
                bottleneck_type="COMPUTE_BOUND",
                confidence="MEDIUM",
                reason=f"SM Throughput ({sm_throughput:.1f}%) å’Œ Memory Throughput ({memory_throughput:.1f}%) éƒ½å¾ˆé«˜ï¼Œè®¡ç®—å•å…ƒæ¥è¿‘é¥±å’Œ",
                suggestions=self.OPTIMIZATIONS["COMPUTE_BOUND"]
            ))
        
        # Occupancy Bound
        if occupancy < 50 and occupancy > 0:
            diagnoses.append(Diagnosis(
                bottleneck_type="OCCUPANCY_BOUND",
                confidence="MEDIUM",
                reason=f"Occupancy ({occupancy:.1f}%) < 50%ï¼Œå¹¶è¡Œåº¦ä¸è¶³",
                suggestions=self.OPTIMIZATIONS["OCCUPANCY_BOUND"]
            ))
        
        if not diagnoses:
            diagnoses.append(Diagnosis(
                bottleneck_type="UNKNOWN or GOOD",
                confidence="LOW",
                reason="æœªæ£€æµ‹åˆ°æ˜æ˜¾ç“¶é¢ˆï¼Œæˆ–æ€§èƒ½å·²æ¥è¿‘æœ€ä¼˜",
                suggestions=[]
            ))
        
        return diagnoses
    
    def status_icon(self, value: float, good_threshold: float, bad_threshold: float, 
                    higher_is_better: bool = True) -> str:
        """è¿”å›çŠ¶æ€å›¾æ ‡"""
        if higher_is_better:
            if value >= good_threshold:
                return "âœ…"
            elif value <= bad_threshold:
                return "âŒ"
            else:
                return "âš ï¸"
        else:
            if value <= good_threshold:
                return "âœ…"
            elif value >= bad_threshold:
                return "âŒ"
            else:
                return "âš ï¸"
    
    def generate_report(self, output_file: Optional[str] = None) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        if not self.kernels:
            return "Error: No kernel data available"
        
        kernel_name, metrics = self.get_user_kernel()
        diagnoses = self.diagnose(metrics)
        
        report = []
        
        # æ ‡é¢˜
        report.append("# NCU è‡ªåŠ¨åŒ–æ€§èƒ½åˆ†ææŠ¥å‘Š")
        report.append("")
        
        # æŠ¥å‘Šä¿¡æ¯
        report.append("## ğŸ“ æŠ¥å‘Šä¿¡æ¯")
        report.append(f"- **Kernel**: `{kernel_name}`")
        if self.report_file:
            report.append(f"- **æŠ¥å‘Šæ–‡ä»¶**: `{self.report_file}`")
        report.append("")
        
        # æ‰§è¡Œæ‘˜è¦
        report.append("## ğŸ“ˆ æ‰§è¡Œæ‘˜è¦")
        report.append("")
        report.append("| é¡¹ç›® | æ•°å€¼ |")
        report.append("|------|------|")
        if diagnoses:
            main_diag = diagnoses[0]
            report.append(f"| **ä¸»è¦ç“¶é¢ˆ** | {main_diag.bottleneck_type} |")
            report.append(f"| **ç½®ä¿¡åº¦** | {main_diag.confidence} |")
        
        duration = metrics.get('duration', 0)
        if duration > 0:
            report.append(f"| **æ‰§è¡Œæ—¶é—´** | {duration:.2f} ms |")
        report.append("")
        
        # å…³é”®æŒ‡æ ‡
        report.append("## ğŸ“Š å…³é”®æŒ‡æ ‡")
        report.append("")
        report.append("### æ€§èƒ½æŒ‡æ ‡")
        report.append("| æŒ‡æ ‡ | æ•°å€¼ | å¥åº·é˜ˆå€¼ | çŠ¶æ€ |")
        report.append("|------|------|----------|------|")
        
        sm_busy = metrics.get('sm_busy', 0)
        if sm_busy > 0:
            report.append(f"| SM Busy | {sm_busy:.2f}% | > 70% | {self.status_icon(sm_busy, 70, 40)} |")
        
        sm_throughput = metrics.get('sm_throughput', 0)
        if sm_throughput > 0:
            report.append(f"| SM Throughput | {sm_throughput:.2f}% | > 60% | {self.status_icon(sm_throughput, 60, 30)} |")
        
        memory_throughput = metrics.get('memory_throughput', 0)
        if memory_throughput > 0:
            report.append(f"| Memory Throughput | {memory_throughput:.2f}% | > 60% | {self.status_icon(memory_throughput, 60, 30)} |")
        
        occupancy = metrics.get('occupancy', 0)
        if occupancy > 0:
            report.append(f"| Occupancy | {occupancy:.2f}% | > 50% | {self.status_icon(occupancy, 50, 25)} |")
        
        report.append("")
        report.append("### å†…å­˜æŒ‡æ ‡")
        report.append("| æŒ‡æ ‡ | æ•°å€¼ | å¥åº·é˜ˆå€¼ | çŠ¶æ€ |")
        report.append("|------|------|----------|------|")
        
        dram = metrics.get('dram_throughput', 0)
        if dram > 0:
            report.append(f"| DRAM Throughput | {dram:.2f}% | < 50% | {self.status_icon(dram, 30, 70, False)} |")
        
        l1tex = metrics.get('l1tex_throughput', 0)
        if l1tex > 0:
            report.append(f"| L1/TEX Throughput | {l1tex:.2f}% | < 80% | {self.status_icon(l1tex, 50, 80, False)} |")
        
        l2 = metrics.get('l2_throughput', 0)
        if l2 > 0:
            report.append(f"| L2 Throughput | {l2:.2f}% | < 80% | {self.status_icon(l2, 50, 80, False)} |")
        
        report.append("")
        
        # é…ç½®ä¿¡æ¯
        report.append("### é…ç½®ä¿¡æ¯")
        report.append("| æŒ‡æ ‡ | æ•°å€¼ |")
        report.append("|------|------|")
        
        block_size = metrics.get('block_size', 0)
        if block_size > 0:
            report.append(f"| Block Size | {int(block_size)} |")
        
        grid_size = metrics.get('grid_size', 0)
        if grid_size > 0:
            report.append(f"| Grid Size | {int(grid_size)} |")
        
        registers = metrics.get('registers', 0)
        if registers > 0:
            report.append(f"| Registers/Thread | {int(registers)} |")
        
        report.append("")
        
        # è¯Šæ–­è¯¦æƒ…
        report.append("## ğŸ” è¯Šæ–­è¯¦æƒ…")
        report.append("")
        
        for i, d in enumerate(diagnoses, 1):
            report.append(f"### {i}. {d.bottleneck_type} (ç½®ä¿¡åº¦: {d.confidence})")
            report.append("")
            report.append(f"**åˆ¤æ–­ä¾æ®**: {d.reason}")
            report.append("")
            
            if d.suggestions:
                report.append("**ä¼˜åŒ–å»ºè®®**:")
                report.append("")
                for j, sug in enumerate(d.suggestions, 1):
                    report.append(f"{j}. **{sug['name']}** (é¢„æœŸæ”¶ç›Š: {sug['gain']}, å¤æ‚åº¦: {sug['complexity']})")
                    report.append(f"   - {sug['action']}")
                    if 'code' in sug:
                        report.append(f"   - ä»£ç ç¤ºä¾‹:")
                        report.append(f"     ```cpp")
                        for line in sug['code'].split('\n'):
                            report.append(f"     {line}")
                        report.append(f"     ```")
                    report.append("")
        
        # ä¸‹ä¸€æ­¥æ“ä½œ
        report.append("## ğŸ› ï¸ ä¸‹ä¸€æ­¥æ“ä½œ")
        report.append("")
        report.append("### å»ºè®®çš„ NCU å‘½ä»¤")
        report.append("```bash")
        if self.report_file:
            base_name = Path(self.report_file).stem
            report.append(f"# ä¼˜åŒ–åé‡æ–°é‡‡é›†")
            report.append(f"ncu --set full -o {base_name}_optimized --target-processes all ./kernel_optimized")
            report.append("")
            report.append(f"# æŸ¥çœ‹å½“å‰æŠ¥å‘Šè¯¦æƒ…")
            report.append(f"ncu --import {self.report_file} --page details")
        report.append("```")
        report.append("")
        
        report.append("### éªŒè¯æ¸…å•")
        report.append("- [ ] å®æ–½å»ºè®®çš„ä¼˜åŒ–")
        report.append("- [ ] é‡æ–°è¿è¡Œ NCU é‡‡é›†")
        report.append("- [ ] å¯¹æ¯”ä¼˜åŒ–å‰åæ•°æ®")
        report.append("- [ ] ç¡®è®¤å…³é”®æŒ‡æ ‡æ”¹å–„")
        report.append("")
        
        report.append("---")
        report.append("")
        report.append("*æŠ¥å‘Šç”± NCU Analyzer è‡ªåŠ¨ç”Ÿæˆ*")
        
        report_text = "\n".join(report)
        
        if output_file:
            with open(output_file, 'w') as f:
                f.write(report_text)
            print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
        
        return report_text
    
    def print_summary(self):
        """æ‰“å°æ‘˜è¦åˆ°æ§åˆ¶å°"""
        if not self.kernels:
            print("âŒ æœªæ‰¾åˆ° kernel æ•°æ®")
            return
        
        kernel_name, metrics = self.get_user_kernel()
        
        print("=" * 60)
        print(f"NCU æ€§èƒ½åˆ†ææ‘˜è¦")
        print("=" * 60)
        print(f"Kernel: {kernel_name[:50]}")
        print()
        
        # å…³é”®æŒ‡æ ‡
        key_metrics = [
            ('SM Busy', 'sm_busy', '%'),
            ('SM Throughput', 'sm_throughput', '%'),
            ('Memory Throughput', 'memory_throughput', '%'),
            ('DRAM Throughput', 'dram_throughput', '%'),
            ('L1/TEX Throughput', 'l1tex_throughput', '%'),
            ('Occupancy', 'occupancy', '%'),
        ]
        
        for name, key, unit in key_metrics:
            value = metrics.get(key, 0)
            if value > 0:
                print(f"{name:25s}: {value:8.2f}{unit}")
        
        print()
        print("è¯Šæ–­ç»“æœ:")
        diagnoses = self.diagnose(metrics)
        for d in diagnoses:
            icon = "ğŸ”´" if d.confidence == "HIGH" else ("ğŸŸ¡" if d.confidence == "MEDIUM" else "ğŸŸ¢")
            print(f"  {icon} {d.bottleneck_type} ({d.confidence})")
        print()


def main():
    parser = argparse.ArgumentParser(
        description='NCU è‡ªåŠ¨åŒ–æ€§èƒ½åˆ†æå·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
    # åˆ†æ ncu-rep æ–‡ä»¶
    python ncu_analyzer.py --import profile.ncu-rep
    
    # åˆ†æå¹¶ä¿å­˜æŠ¥å‘Š
    python ncu_analyzer.py --import profile.ncu-rep -o analysis.md
        """
    )
    parser.add_argument('--import', dest='import_file', help='ä» ncu-rep æ–‡ä»¶åˆ†æ')
    parser.add_argument('-o', '--output', help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶ (.md)')
    parser.add_argument('--json', action='store_true', help='ä»¥ JSON æ ¼å¼è¾“å‡ºæŒ‡æ ‡')
    
    args = parser.parse_args()
    
    analyzer = NCUAnalyzer()
    
    if args.import_file:
        print(f"ğŸ“¥ æ­£åœ¨åˆ†æ NCU æŠ¥å‘Š: {args.import_file}")
        kernels = analyzer.extract_from_ncu_rep(args.import_file)
        if not kernels:
            print("âŒ æœªèƒ½ä»æŠ¥å‘Šä¸­æå–æ•°æ®")
            return
        print(f"âœ… æ‰¾åˆ° {len(kernels)} ä¸ª kernel")
        # Debug: print raw metrics
        for name, metrics in kernels.items():
            if 'mysgemm' in name.lower() or 'kernel' in name.lower():
                print(f"\nè°ƒè¯• - {name} çš„åŸå§‹æŒ‡æ ‡:")
                for k, v in list(metrics.items())[:10]:
                    print(f"  {k}: {v}")
    else:
        parser.print_help()
        return
    
    if args.json:
        print(json.dumps(analyzer.kernels, indent=2))
    else:
        analyzer.print_summary()
        report = analyzer.generate_report(args.output)
        if not args.output:
            print()
            print(report)


if __name__ == "__main__":
    main()
