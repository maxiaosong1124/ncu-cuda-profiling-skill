#!/usr/bin/env python3
"""
NCU CUDA Optimizer v2 - Enhanced with Comprehensive Metrics
æ”¯æŒäº¤äº’å¼å’Œå…¨è‡ªåŠ¨ä¸¤ç§ä¼˜åŒ–æ¨¡å¼ï¼ŒåŒ…å«å®Œæ•´çš„ NCU æŒ‡æ ‡è§£æ
"""

import os
import re
import sys
import json
import shutil
import subprocess
import tempfile
from dataclasses import dataclass, field, asdict
from typing import List, Dict, Optional, Tuple, Callable
from pathlib import Path
from datetime import datetime
import argparse

from strategy_library import (
    CUDAStrategyLibrary,
    BottleneckType,
    diagnose_and_recommend
)


@dataclass
class OptimizationVersion:
    """ä¼˜åŒ–ç‰ˆæœ¬è®°å½•"""
    version_id: str
    iteration: int
    code_path: str
    strategy_name: str
    strategy_description: str
    metrics: Dict[str, float]
    speedup_vs_baseline: float
    speedup_vs_previous: float
    build_success: bool
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())


@dataclass
class OptimizationState:
    """ä¼˜åŒ–çŠ¶æ€"""
    project_dir: str
    source_file: str
    baseline_code: str
    baseline_metrics: Dict[str, float]
    versions: List[OptimizationVersion] = field(default_factory=list)
    current_iteration: int = 0
    best_version_id: str = "baseline"
    converged: bool = False
    convergence_reason: str = ""


class NCUProfiler:
    """NCU æ€§èƒ½åˆ†æå™¨ - æ”¯æŒå…¨é‡æŒ‡æ ‡é‡‡é›†å’Œè§£æ"""

    def __init__(self, ncu_path: str = "ncu"):
        self.ncu_path = ncu_path
        # æ‰©å±•çš„æŒ‡æ ‡åç§°æ˜ å°„ (ä½¿ç”¨å­å­—ç¬¦ä¸²åŒ¹é…)
        # æŒ‰ç…§åˆ†æä¼˜å…ˆçº§æ’åº
        self.metrics_map = {
            # === Speed Of Light Throughput (é¦–è¦) ===
            "gpu_time": "gpu__time_duration.avg",
            "memory_throughput": "gpu__memory_throughput.avg.pct",
            "dram_throughput": "gpu__dram_throughput.avg.pct",
            "sm_throughput": "sm__throughput.avg.pct",
            "l1tex_throughput": "l1tex__throughput.avg.pct",
            "l2_throughput": "lts__throughput.avg.pct",
            
            # === Compute Workload Analysis ===
            "sm_busy": "sm__cycles_active.avg.pct",
            "issue_slots_busy": "smsp__issue_active.avg.pct",
            "executed_ipc_active": "smsp__ipc.avg",
            
            # === Memory Workload Analysis ===
            "l1_hit_rate": "l1tex__t_sector_hit_rate.pct",
            "l2_hit_rate": "lts__t_sector_hit_rate.pct",
            "mem_busy": "gpu__mem_busy.avg.pct",
            
            # === Occupancy ===
            "occupancy": "sm__occupancy.avg.pct",
            "theoretical_occupancy": "sm__theoretical_occupancy.avg.pct",
            
            # === Scheduler Statistics ===
            "active_warps": "smsp__warps_active.avg",
            "eligible_warps": "smsp__warps_eligible.avg",
            "issued_warps": "smsp__issue_warps.avg",
            "no_eligible": "smsp__warps_no_eligible.avg.pct",
            
            # === Warp State Statistics (Stall Reasons) ===
            "stall_wait": "smsp__warp_issue_stalled_wait.avg.pct",
            "stall_barrier": "smsp__warp_issue_stalled_barrier.avg.pct",
            "stall_memory_dependency": "smsp__warp_issue_stalled_memory_dependency.avg.pct",
            "stall_execution_dependency": "smsp__warp_issue_stalled_execution_dependency.avg.pct",
            "stall_memory_throttle": "smsp__warp_issue_stalled_memory_throttle.avg.pct",
            "stall_instruction_fetch": "smsp__warp_issue_stalled_inst_fetch.avg.pct",
            "stall_texture": "smsp__warp_issue_stalled_texture.avg.pct",
            "stall_constant": "smsp__warp_issue_stalled_constant_memory_dependency.avg.pct",
            "stall_not_selected": "smsp__warp_issue_stalled_not_selected.avg.pct",
            
            # === Launch Statistics ===
            "registers_per_thread": "launch__registers_per_thread",
            "shared_memory_per_block": "launch__shared_mem_configured_size",
            "block_size": "launch__block_size",
            "grid_size": "launch__grid_size",
        }

    def profile_from_report(self, report_path: str) -> Tuple[bool, Dict[str, float]]:
        """
        ä»å·²æœ‰çš„ NCU æŠ¥å‘Šæ–‡ä»¶å¯¼å…¥åˆ†æ

        Args:
            report_path: .ncu-rep æ–‡ä»¶è·¯å¾„

        Returns:
            (success, metrics)
        """
        if not os.path.exists(report_path):
            print(f"æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨: {report_path}")
            return False, {}

        # åˆ›å»ºä¸´æ—¶ CSV
        temp_dir = tempfile.mkdtemp()
        csv_path = os.path.join(temp_dir, "imported_metrics.csv")

        try:
            # å¯¼å‡º CSV
            cmd = [
                self.ncu_path,
                "--import", report_path,
                "--page", "raw",
                "--csv"
            ]

            with open(csv_path, 'w') as f:
                result = subprocess.run(cmd, stdout=f, timeout=60)
                if result.returncode != 0:
                    return False, {}

            # è§£ææŒ‡æ ‡
            metrics = self._parse_metrics(csv_path)
            return True, metrics

        except Exception as e:
            print(f"å¯¼å…¥æŠ¥å‘Šå¤±è´¥: {e}")
            return False, {}
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)

    def profile(self, executable: str, report_name: str) -> Tuple[bool, Dict[str, float]]:
        """
        è¿è¡Œ NCU æ€§èƒ½åˆ†æ

        Returns:
            (success, metrics)
        """
        report_path = f"{report_name}.ncu-rep"
        csv_path = f"{report_name}.csv"

        # è¿è¡Œ NCU é‡‡é›†
        cmd = [
            self.ncu_path,
            "--set", "full",
            "-o", report_name,
            "--target-processes", "all",
            "--force-overwrite",
            executable
        ]

        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=300
            )

            if result.returncode != 0 and not os.path.exists(report_path):
                print(f"NCU è¿è¡Œå¤±è´¥: {result.stderr}")
                return False, {}

            # å¯¼å‡º CSV
            self._export_csv(report_path, csv_path)

            # è§£ææŒ‡æ ‡
            metrics = self._parse_metrics(csv_path)
            return True, metrics

        except subprocess.TimeoutExpired:
            print("NCU åˆ†æè¶…æ—¶")
            return False, {}
        except Exception as e:
            print(f"NCU åˆ†æå¼‚å¸¸: {e}")
            return False, {}

    def _export_csv(self, report_path: str, csv_path: str):
        """å¯¼å‡º CSV æ ¼å¼æŠ¥å‘Š"""
        cmd = [
            self.ncu_path,
            "--import", report_path,
            "--page", "raw",
            "--csv"
        ]

        try:
            with open(csv_path, 'w') as f:
                subprocess.run(cmd, stdout=f, timeout=60)
        except Exception as e:
            print(f"CSV å¯¼å‡ºå¤±è´¥: {e}")

    def _parse_metrics(self, csv_path: str) -> Dict[str, float]:
        """
        è§£æ NCU CSV æŠ¥å‘Šæå–å…³é”®æŒ‡æ ‡
        
        æ”¯æŒå…¨é‡æŒ‡æ ‡è§£æï¼ŒåŒ…æ‹¬ï¼š
        - Speed Of Light Throughput
        - Compute Workload Analysis
        - Memory Workload Analysis
        - Occupancy
        - Scheduler Statistics
        - Warp State Statistics
        """
        metrics = {}

        if not os.path.exists(csv_path):
            return metrics

        try:
            import csv
            with open(csv_path, 'r', newline='') as f:
                reader = csv.reader(f)
                rows = list(reader)

            if len(rows) < 3:
                return metrics

            # æ‰¾åˆ° kernel æ‰§è¡Œè¡Œ
            header = rows[0]

            # NCU CSV æ ¼å¼ï¼šç¬¬0è¡Œæ˜¯è¡¨å¤´ï¼Œç¬¬1è¡Œæ˜¯ç©ºè¡Œ/å•ä½è¡Œï¼Œç¬¬2è¡Œå¼€å§‹æ˜¯æ•°æ®
            # ä»ç¬¬3è¡Œå¼€å§‹è¯»å–å®é™…æ•°æ®ï¼ˆç´¢å¼•2ï¼‰
            for row_data in rows[2:]:
                if len(row_data) != len(header):
                    continue

                row = dict(zip(header, row_data))

                # æå–å…³é”®æŒ‡æ ‡ (ä½¿ç”¨å­å­—ç¬¦ä¸²åŒ¹é…)
                for key, metric_pattern in self.metrics_map.items():
                    # æŸ¥æ‰¾åŒ¹é…çš„åˆ—
                    for col_name, col_value in row.items():
                        if metric_pattern in col_name:
                            try:
                                # å¤„ç†å¸¦å•ä½çš„å€¼ (å¦‚ "17.66 us", "8.34 %")
                                clean_value = col_value.replace('"', '').strip()
                                # åˆ†å‰²æ•°å€¼å’Œå•ä½
                                parts = clean_value.split()
                                if parts:
                                    # ç¡®ä¿ç¬¬ä¸€ä¸ªéƒ¨åˆ†æ˜¯æ•°å­—
                                    value = float(parts[0])
                                    metrics[key] = value
                                    # è®°å½•æ—¶é—´å•ä½ç”¨äºåç»­è½¬æ¢
                                    if 'time' in key and len(parts) > 1:
                                        metrics[key + '_unit'] = parts[1]
                            except (ValueError, TypeError, IndexError):
                                pass
                            break  # æ‰¾åˆ°ç¬¬ä¸€ä¸ªåŒ¹é…å°±åœæ­¢

                # å¦‚æœæœ‰ kernel åç§°ï¼Œè®°å½•ä¸‹æ¥
                if 'Kernel Name' in row:
                    metrics['kernel_name'] = row['Kernel Name']

                # åªå¤„ç†ç¬¬ä¸€ä¸ªæœ‰æ•ˆçš„ kernel è¡Œ
                if metrics.get('gpu_time'):
                    break

        except Exception as e:
            print(f"è§£ææŒ‡æ ‡å¤±è´¥: {e}")

        return metrics

    def print_metrics_summary(self, metrics: Dict[str, float]):
        """æ‰“å°æŒ‡æ ‡æ‘˜è¦ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
        print("\n" + "="*60)
        print("NCU Metrics Summary")
        print("="*60)
        
        # Speed Of Light
        print("\nğŸ“Š Speed Of Light Throughput:")
        for key in ['memory_throughput', 'dram_throughput', 'sm_throughput', 
                    'l1tex_throughput', 'l2_throughput']:
            if key in metrics:
                print(f"  {key}: {metrics[key]:.2f}%")
        
        # Compute
        print("\nğŸ”¢ Compute Workload:")
        for key in ['sm_busy', 'issue_slots_busy', 'executed_ipc_active']:
            if key in metrics:
                print(f"  {key}: {metrics[key]:.2f}")
        
        # Memory
        print("\nğŸ’¾ Memory Workload:")
        for key in ['l1_hit_rate', 'l2_hit_rate', 'mem_busy']:
            if key in metrics:
                print(f"  {key}: {metrics[key]:.2f}%")
        
        # Occupancy
        print("\nğŸ“ˆ Occupancy:")
        for key in ['occupancy', 'theoretical_occupancy']:
            if key in metrics:
                print(f"  {key}: {metrics[key]:.2f}%")
        
        # Scheduler
        print("\nâš¡ Scheduler Stats:")
        for key in ['active_warps', 'eligible_warps', 'no_eligible']:
            if key in metrics:
                print(f"  {key}: {metrics[key]:.2f}")
        
        # Stall Reasons
        print("\nâ¸ï¸  Warp Stall Reasons:")
        stall_keys = [k for k in metrics.keys() if k.startswith('stall_')]
        for key in sorted(stall_keys):
            print(f"  {key}: {metrics[key]:.2f}%")
        
        print("="*60 + "\n")


class CodeModifier:
    """CUDA ä»£ç ä¿®æ”¹å™¨"""

    def __init__(self, strategy_library: CUDAStrategyLibrary):
        self.library = strategy_library

    def apply_strategy(
        self,
        code: str,
        strategy_name: str,
        params: Dict[str, any]
    ) -> Tuple[bool, str]:
        """
        åº”ç”¨ä¼˜åŒ–ç­–ç•¥åˆ°ä»£ç 

        Returns:
            (success, modified_code)
        """
        strategy = self.library.get_strategy(strategy_name)
        if not strategy:
            return False, code

        # ç”Ÿæˆä¼˜åŒ–ä»£ç ç‰‡æ®µ
        optimization_code = self.library.generate_optimization_code(
            strategy_name, params
        )

        # æ ¹æ®ç­–ç•¥ç±»å‹åº”ç”¨ä¿®æ”¹
        if strategy_name == "block_tiling":
            return self._apply_block_tiling(code, optimization_code, params)
        elif strategy_name == "smem_padding":
            return self._apply_smem_padding(code, params)
        elif strategy_name == "vectorized_load":
            return self._apply_vectorized_load(code, params)
        elif strategy_name == "loop_unrolling":
            return self._apply_loop_unrolling(code, params)
        elif strategy_name == "register_opt":
            return self._apply_register_opt(code, params)
        elif strategy_name == "warp_primitives":
            return self._apply_warp_primitives(code, params)
        elif strategy_name == "double_buffering":
            return self._apply_double_buffering(code, params)
        else:
            # é€šç”¨ç­–ç•¥ï¼šåœ¨ kernel å¼€å¤´æ’å…¥ä¼˜åŒ–ä»£ç 
            return self._insert_at_kernel_start(code, optimization_code)

    def _apply_block_tiling(
        self,
        code: str,
        optimization_code: str,
        params: Dict
    ) -> Tuple[bool, str]:
        """åº”ç”¨ Block Tiling ä¼˜åŒ–"""
        lines = code.split('\n')
        modified = []
        inserted = False

        for i, line in enumerate(lines):
            # åœ¨ kernel å‡½æ•°å¼€å§‹åæ’å…¥å…±äº«å†…å­˜å£°æ˜
            if '__global__' in line and 'void' in line and not inserted:
                modified.append(line)
                # æ‰¾åˆ°å‡½æ•°ä½“çš„å¼€å§‹
                j = i + 1
                while j < len(lines) and '{' not in lines[j]:
                    modified.append(lines[j])
                    j += 1
                if j < len(lines):
                    modified.append(lines[j])  # {
                    # æ’å…¥å…±äº«å†…å­˜å£°æ˜
                    bm = params.get('bm', 32)
                    bn = params.get('bn', 32)
                    bk = params.get('bk', 8)
                    modified.append(f'    // Block Tiling Optimization')
                    modified.append(f'    const int BM = {bm};')
                    modified.append(f'    const int BN = {bn};')
                    modified.append(f'    const int BK = {bk};')
                    modified.append(f'    __shared__ float As[BM][BK];')
                    modified.append(f'    __shared__ float Bs[BK][BN];')
                    inserted = True
                    i = j
            else:
                modified.append(line)

        return inserted, '\n'.join(modified)

    def _apply_smem_padding(
        self,
        code: str,
        params: Dict
    ) -> Tuple[bool, str]:
        """åº”ç”¨ Shared Memory Padding"""
        pad = params.get('pad', 1)

        # æŸ¥æ‰¾å…±äº«å†…å­˜å£°æ˜å¹¶æ·»åŠ  padding
        pattern = r'(__shared__\s+\w+\s+\w+)\[(\d+)\]\[(\d+)\]'

        def replace_with_padding(match):
            base = match.group(1)
            dim1 = match.group(2)
            dim2 = match.group(3)
            return f'{base}[{dim1}][{dim2} + {pad}]  // Padding to avoid bank conflict'

        modified_code = re.sub(pattern, replace_with_padding, code)
        success = modified_code != code

        return success, modified_code

    def _apply_vectorized_load(
        self,
        code: str,
        params: Dict
    ) -> Tuple[bool, str]:
        """åº”ç”¨ Vectorized Load ä¼˜åŒ–"""
        modified = code

        # æ·»åŠ  float4 ç±»å‹å®šä¹‰ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if 'float4' not in code:
            modified = 'struct alignas(16) float4 { float x, y, z, w; };\n' + modified

        return True, modified

    def _apply_loop_unrolling(
        self,
        code: str,
        params: Dict
    ) -> Tuple[bool, str]:
        """åº”ç”¨ Loop Unrolling ä¼˜åŒ–"""
        unroll_factor = params.get('unroll_factor', 4)

        # æŸ¥æ‰¾ for å¾ªç¯å¹¶æ·»åŠ  #pragma unroll
        pattern = r'(\n\s*)(for\s*\(\s*int\s+(\w+)\s*=\s*0)'

        def add_pragma(match):
            indent = match.group(1)
            loop_start = match.group(2)
            return f'{indent}#pragma unroll {unroll_factor}{indent}{loop_start}'

        modified_code = re.sub(pattern, add_pragma, code)
        success = modified_code != code

        return success, modified_code

    def _apply_register_opt(
        self,
        code: str,
        params: Dict
    ) -> Tuple[bool, str]:
        """åº”ç”¨ Register ä¼˜åŒ–"""
        max_threads = params.get('max_threads', 256)
        min_blocks = params.get('min_blocks', 2)

        # åœ¨ __global__ å‰æ·»åŠ  __launch_bounds__
        pattern = r'(__global__\s+void)'
        replacement = f'__launch_bounds__({max_threads}, {min_blocks})\n__global__ void'

        modified_code = re.sub(pattern, replacement, code)
        success = modified_code != code

        return success, modified_code

    def _apply_warp_primitives(
        self,
        code: str,
        params: Dict
    ) -> Tuple[bool, str]:
        """åº”ç”¨ Warp-level Primitives ä¼˜åŒ–"""
        # è¿™æ˜¯ä¸€ä¸ªå¤æ‚çš„è½¬æ¢ï¼Œç®€åŒ–ç‰ˆæœ¬åªæ·»åŠ æ³¨é‡Šæç¤º
        marker = '// WARP_PRIMITIVE_OPTIMIZATION: Consider using __shfl_down_sync for reduction'
        if marker in code:
            return False, code

        # åœ¨åŒ…å« __syncthreads çš„è§„çº¦æ“ä½œé™„è¿‘æ·»åŠ æç¤º
        lines = code.split('\n')
        modified = []

        for line in lines:
            modified.append(line)
            if '__syncthreads()' in line:
                modified.append(marker)

        return True, '\n'.join(modified)

    def _apply_double_buffering(
        self,
        code: str,
        params: Dict
    ) -> Tuple[bool, str]:
        """åº”ç”¨ Double Buffering ä¼˜åŒ–"""
        # ç®€åŒ–å®ç°ï¼šåœ¨ kernel å¼€å¤´æ·»åŠ åŒç¼“å†²å£°æ˜
        bm = params.get('bm', 32)
        bn = params.get('bn', 32)
        bk = params.get('bk', 8)

        lines = code.split('\n')
        modified = []
        inserted = False

        for i, line in enumerate(lines):
            if '__global__' in line and 'void' in line and not inserted:
                modified.append(line)
                j = i + 1
                while j < len(lines) and '{' not in lines[j]:
                    modified.append(lines[j])
                    j += 1
                if j < len(lines):
                    modified.append(lines[j])
                    modified.append(f'    // Double Buffering Optimization')
                    modified.append(f'    __shared__ float As[2][{bm}][{bk}];')
                    modified.append(f'    __shared__ float Bs[2][{bk}][{bn}];')
                    modified.append(f'    int compute_stage = 0, load_stage = 0;')
                    inserted = True
                    i = j
            else:
                modified.append(line)

        return inserted, '\n'.join(modified)

    def _insert_at_kernel_start(
        self,
        code: str,
        optimization_code: str
    ) -> Tuple[bool, str]:
        """åœ¨ kernel å‡½æ•°å¼€å¤´æ’å…¥ä»£ç """
        lines = code.split('\n')
        modified = []
        inserted = False

        for i, line in enumerate(lines):
            if '__global__' in line and not inserted:
                modified.append(line)
                # æ‰¾åˆ° {
                j = i + 1
                while j < len(lines) and '{' not in lines[j]:
                    modified.append(lines[j])
                    j += 1
                if j < len(lines):
                    modified.append(lines[j])
                    modified.append(optimization_code)
                    inserted = True
                    i = j
            else:
                modified.append(line)

        return inserted, '\n'.join(modified)


class CUDAOptimizer:
    """CUDA ä¼˜åŒ–å™¨ä¸»ç±»"""

    CONVERGENCE_THRESHOLD = 0.03  # 3% æå‡é˜ˆå€¼
    MAX_ITERATIONS = 5

    def __init__(
        self,
        source_file: str,
        build_command: str,
        mode: str = "auto",
        ncu_path: str = "ncu"
    ):
        self.source_file = Path(source_file)
        self.build_command = build_command
        self.mode = mode
        self.ncu_profiler = NCUProfiler(ncu_path)
        self.strategy_library = CUDAStrategyLibrary()
        self.code_modifier = CodeModifier(self.strategy_library)

        # åˆ›å»ºå·¥ä½œç›®å½•
        self.work_dir = Path(tempfile.mkdtemp(prefix="ncu_opt_"))
        self.state = None

    def analyze_only(self, save_to_project: bool = True) -> Dict:
        """
        ä»…åˆ†ææ€§èƒ½ï¼Œä¸æ‰§è¡Œä¼˜åŒ– (å¯¹åº” v1 åŠŸèƒ½)

        Args:
            save_to_project: æ˜¯å¦å°†æŠ¥å‘Šä¿å­˜åˆ°é¡¹ç›®ç›®å½•

        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        print(f"{'='*60}")
        print("NCU CUDA Profiler - Analysis Mode (v2 Enhanced)")
        print(f"{'='*60}")
        print(f"Source: {self.source_file}")
        print()

        # ç¼–è¯‘
        executable = self.work_dir / "analyze_target"
        if not self._build(str(self.source_file), str(executable)):
            return {"success": False, "error": "Failed to build target"}

        # è¿è¡Œ NCU
        success, metrics = self.ncu_profiler.profile(
            str(executable),
            str(self.work_dir / "analysis_report")
        )

        if not success:
            return {"success": False, "error": "Failed to profile"}

        # æ‰“å°å®Œæ•´æŒ‡æ ‡æ‘˜è¦
        self.ncu_profiler.print_metrics_summary(metrics)

        # è¯Šæ–­ç“¶é¢ˆ
        bottleneck = self.strategy_library.diagnose_bottleneck(metrics)
        recommendations = self.strategy_library.get_strategies_for_bottleneck(
            bottleneck, metrics
        )

        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        report = self._generate_analysis_report(metrics, bottleneck, recommendations)

        # ä¿å­˜åˆ°é¡¹ç›®ç›®å½• (å¦‚æœéœ€è¦)
        if save_to_project:
            self._save_to_project_dir(report, metrics)

        return {
            "success": True,
            "metrics": metrics,
            "bottleneck": bottleneck.value,
            "recommendations": [r.name for r in recommendations[:3]],
            "report": report
        }

    def analyze_from_report(self, report_path: str) -> Dict:
        """
        ä»å·²æœ‰çš„ NCU æŠ¥å‘Šåˆ†æ (å¯¹åº” v1 åŠŸèƒ½)

        Args:
            report_path: .ncu-rep æ–‡ä»¶è·¯å¾„

        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        print(f"{'='*60}")
        print("NCU CUDA Profiler - Import Mode (v2 Enhanced)")
        print(f"{'='*60}")
        print(f"Report: {report_path}")
        print()

        # ä»æŠ¥å‘Šå¯¼å…¥
        success, metrics = self.ncu_profiler.profile_from_report(report_path)

        if not success:
            return {"success": False, "error": "Failed to import report"}

        # æ‰“å°å®Œæ•´æŒ‡æ ‡æ‘˜è¦
        self.ncu_profiler.print_metrics_summary(metrics)

        # è¯Šæ–­ç“¶é¢ˆ
        bottleneck = self.strategy_library.diagnose_bottleneck(metrics)
        recommendations = self.strategy_library.get_strategies_for_bottleneck(
            bottleneck, metrics
        )

        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        report = self._generate_analysis_report(metrics, bottleneck, recommendations)

        return {
            "success": True,
            "metrics": metrics,
            "bottleneck": bottleneck.value,
            "recommendations": [r.name for r in recommendations[:3]],
            "report": report
        }

    def _save_to_project_dir(self, report: str, metrics: Dict):
        """ä¿å­˜åˆ†æç»“æœåˆ°é¡¹ç›®ç›®å½• (v1 åŠŸèƒ½)"""
        # åˆ›å»º ncu_reports ç›®å½•
        reports_dir = Path("ncu_reports")
        reports_dir.mkdir(exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        source_name = Path(self.source_file).stem

        # ä¿å­˜æŠ¥å‘Š
        report_path = reports_dir / f"{source_name}_{timestamp}_analysis.md"
        with open(report_path, 'w') as f:
            f.write(report)

        # ä¿å­˜æŒ‡æ ‡ JSON
        metrics_path = reports_dir / f"{source_name}_{timestamp}_metrics.json"
        with open(metrics_path, 'w') as f:
            json.dump(metrics, f, indent=2)

        print(f"\nğŸ“ Report saved to: {report_path}")
        print(f"ğŸ“Š Metrics saved to: {metrics_path}")

    def _generate_analysis_report(
        self,
        metrics: Dict[str, float],
        bottleneck: 'BottleneckType',
        recommendations: List
    ) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š (v2 å¢å¼ºç‰ˆ)"""
        report_lines = [
            "# NCU æ€§èƒ½åˆ†ææŠ¥å‘Š (v2)",
            "",
            f"**åˆ†ææ—¶é—´**: {datetime.now().isoformat()}",
            f"**æºæ–‡ä»¶**: {self.source_file}",
            "",
            "## æ‰§è¡Œæ‘˜è¦",
            "",
            f"| é¡¹ç›® | æ•°å€¼ |",
            f"|------|------|",
            f"| **ä¸»è¦ç“¶é¢ˆ** | {bottleneck.value} |",
            f"| **GPU æ‰§è¡Œæ—¶é—´** | {metrics.get('gpu_time', 'N/A')} Î¼s |",
        ]
        
        # Speed Of Light Throughput
        report_lines.extend([
            "",
            "## Speed Of Light Throughput",
            "",
            "| æŒ‡æ ‡ | æ•°å€¼ | çŠ¶æ€ |",
            "|------|------|------|",
        ])
        for key in ['memory_throughput', 'dram_throughput', 'sm_throughput', 'l1tex_throughput']:
            if key in metrics:
                val = metrics[key]
                status = "âš ï¸" if val > 80 else "âœ…"
                report_lines.append(f"| {key} | {val:.2f}% | {status} |")
        
        # Compute Workload
        report_lines.extend([
            "",
            "## Compute Workload",
            "",
            "| æŒ‡æ ‡ | æ•°å€¼ |",
            "|------|------|",
        ])
        for key in ['sm_busy', 'issue_slots_busy', 'executed_ipc_active']:
            if key in metrics:
                report_lines.append(f"| {key} | {metrics[key]:.2f} |")
        
        # Memory Workload
        report_lines.extend([
            "",
            "## Memory Workload",
            "",
            "| æŒ‡æ ‡ | æ•°å€¼ |",
            "|------|------|",
        ])
        for key in ['l1_hit_rate', 'l2_hit_rate']:
            if key in metrics:
                report_lines.append(f"| {key} | {metrics[key]:.2f}% |")
        
        # Occupancy
        report_lines.extend([
            "",
            "## Occupancy",
            "",
            "| æŒ‡æ ‡ | æ•°å€¼ |",
            "|------|------|",
        ])
        for key in ['occupancy', 'theoretical_occupancy']:
            if key in metrics:
                report_lines.append(f"| {key} | {metrics[key]:.2f}% |")
        
        # Warp Stall Reasons
        stall_keys = [k for k in metrics.keys() if k.startswith('stall_')]
        if stall_keys:
            report_lines.extend([
                "",
                "## Warp Stall Reasons",
                "",
                "| æŒ‡æ ‡ | æ•°å€¼ |",
                "|------|------|",
            ])
            for key in sorted(stall_keys):
                report_lines.append(f"| {key} | {metrics[key]:.2f}% |")
        
        # å…³é”®æŒ‡æ ‡æ±‡æ€»
        report_lines.extend([
            "",
            "## å…³é”®æŒ‡æ ‡æ±‡æ€»",
            "",
            "| æŒ‡æ ‡ | æ•°å€¼ |",
            "|------|------|",
        ])

        for key, value in metrics.items():
            if not key.endswith('_unit') and not key.startswith('stall_'):
                if isinstance(value, float):
                    report_lines.append(f"| {key} | {value:.2f} |")
                else:
                    report_lines.append(f"| {key} | {value} |")

        report_lines.extend([
            "",
            "## è¯Šæ–­è¯¦æƒ…",
            "",
            f"**ç“¶é¢ˆç±»å‹**: {bottleneck.value}",
            "",
            "**ä¼˜åŒ–å»ºè®®**:",
            ""
        ])

        for i, strategy in enumerate(recommendations[:3], 1):
            report_lines.extend([
                f"{i}. **{strategy.name}** (é¢„æœŸ {strategy.expected_speedup}x æå‡)",
                f"   - {strategy.description}",
                f"   - å¤æ‚åº¦: {strategy.complexity}",
                ""
            ])

        return '\n'.join(report_lines)

    def run(self) -> Dict:
        """
        è¿è¡Œä¼˜åŒ–æµç¨‹

        Returns:
            ä¼˜åŒ–ç»“æœå­—å…¸
        """
        print(f"{'='*60}")
        print(f"NCU CUDA Optimizer v2 - {self.mode.upper()} Mode")
        print(f"{'='*60}")
        print(f"Source: {self.source_file}")
        print(f"Work Directory: {self.work_dir}")
        print(f"Max Iterations: {self.MAX_ITERATIONS}")
        print(f"Convergence Threshold: {self.CONVERGENCE_THRESHOLD*100}%")
        print()

        # 1. ä¿å­˜ baseline
        if not self._setup_baseline():
            return {"success": False, "error": "Failed to setup baseline"}

        # 2. è¿è¡Œä¼˜åŒ–å¾ªç¯
        while self.state.current_iteration < self.MAX_ITERATIONS:
            if self.state.converged:
                break

            self.state.current_iteration += 1
            print(f"\n{'-'*60}")
            print(f"Iteration {self.state.current_iteration}/{self.MAX_ITERATIONS}")
            print(f"{'-'*60}")

            success = self._run_iteration()
            if not success:
                print(f"Iteration {self.state.current_iteration} failed, stopping...")
                break

        # 3. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        return self._generate_report()

    def _setup_baseline(self) -> bool:
        """è®¾ç½® baseline"""
        print("Setting up baseline...")

        # è¯»å–æºä»£ç 
        try:
            with open(self.source_file, 'r') as f:
                baseline_code = f.read()
        except Exception as e:
            print(f"Failed to read source file: {e}")
            return False

        # ä¿å­˜ baseline åˆ°å·¥ä½œç›®å½•
        baseline_path = self.work_dir / "baseline.cu"
        with open(baseline_path, 'w') as f:
            f.write(baseline_code)

        # ç¼–è¯‘å¹¶åˆ†æ baseline
        executable = self.work_dir / "baseline"
        if not self._build(str(baseline_path), str(executable)):
            print("Failed to build baseline")
            return False

        success, metrics = self.ncu_profiler.profile(
            str(executable),
            str(self.work_dir / "baseline_report")
        )

        if not success:
            print("Failed to profile baseline")
            return False

        # æ‰“å°æŒ‡æ ‡æ‘˜è¦
        self.ncu_profiler.print_metrics_summary(metrics)

        self.state = OptimizationState(
            project_dir=str(self.work_dir),
            source_file=str(self.source_file),
            baseline_code=baseline_code,
            baseline_metrics=metrics,
            current_iteration=0,
            versions=[]
        )

        return True

    def _run_iteration(self) -> bool:
        """è¿è¡Œå•æ¬¡ä¼˜åŒ–è¿­ä»£"""
        iteration = self.state.current_iteration

        # è·å–å½“å‰æœ€ä½³ç‰ˆæœ¬çš„ä»£ç 
        current_code = self._get_best_code()

        # è¯Šæ–­ç“¶é¢ˆ
        current_metrics = self._get_best_metrics()
        bottleneck = self.strategy_library.diagnose_bottleneck(current_metrics)
        print(f"\nDiagnosed bottleneck: {bottleneck.value}")

        # è·å–æ¨èç­–ç•¥
        strategies = self.strategy_library.get_strategies_for_bottleneck(
            bottleneck, current_metrics
        )

        if not strategies:
            print("No applicable strategies found")
            self.state.converged = True
            self.state.convergence_reason = "No applicable strategies"
            return False

        # é€‰æ‹©ç­–ç•¥
        selected_strategy = strategies[0]
        print(f"Selected strategy: {selected_strategy.name}")
        print(f"  Description: {selected_strategy.description}")
        print(f"  Expected speedup: {selected_strategy.expected_speedup}x")

        # äº¤äº’å¼æ¨¡å¼ï¼šè¯¢é—®ç”¨æˆ·ç¡®è®¤
        if self.mode == "interactive":
            if not self._ask_user_confirmation(selected_strategy):
                print("User skipped this strategy")
                return self._try_next_strategy(strategies[1:], current_code)

        # ç”Ÿæˆç­–ç•¥å‚æ•°
        params = self._generate_strategy_params(selected_strategy.name)

        # åº”ç”¨ä¼˜åŒ–
        success, modified_code = self.code_modifier.apply_strategy(
            current_code,
            selected_strategy.name,
            params
        )

        if not success:
            print(f"Failed to apply strategy: {selected_strategy.name}")
            return self._try_next_strategy(strategies[1:], current_code)

        # ä¿å­˜æ–°ç‰ˆæœ¬
        version_id = f"v{iteration}"
        version_path = self.work_dir / f"{version_id}.cu"
        with open(version_path, 'w') as f:
            f.write(modified_code)

        # ç¼–è¯‘æ–°ç‰ˆæœ¬
        executable = self.work_dir / version_id
        if not self._build(str(version_path), str(executable)):
            print(f"Build failed for {version_id}")
            return False

        # æ€§èƒ½æµ‹è¯•
        success, new_metrics = self.ncu_profiler.profile(
            str(executable),
            str(self.work_dir / f"{version_id}_report")
        )

        if not success:
            print(f"Profiling failed for {version_id}")
            return False

        # è®¡ç®—åŠ é€Ÿæ¯”
        speedup_vs_baseline = self._calculate_speedup(
            new_metrics, self.state.baseline_metrics
        )
        speedup_vs_previous = self._calculate_speedup(
            new_metrics, current_metrics
        )

        print(f"\nResults:")
        print(f"  Speedup vs baseline: {speedup_vs_baseline:.2f}x")
        print(f"  Speedup vs previous: {speedup_vs_previous:.2f}x")

        # åˆ›å»ºç‰ˆæœ¬è®°å½•
        version = OptimizationVersion(
            version_id=version_id,
            iteration=iteration,
            code_path=str(version_path),
            strategy_name=selected_strategy.name,
            strategy_description=selected_strategy.description,
            metrics=new_metrics,
            speedup_vs_baseline=speedup_vs_baseline,
            speedup_vs_previous=speedup_vs_previous,
            build_success=True
        )
        self.state.versions.append(version)

        # æ£€æŸ¥æ˜¯å¦æ€§èƒ½ä¸‹é™ï¼Œéœ€è¦å›æ»š
        if speedup_vs_previous < 0.95:  # ä¸‹é™è¶…è¿‡ 5%
            print(f"âš ï¸  Performance regression detected ({speedup_vs_previous:.2f}x)")
            print("Auto-rolling back to previous version...")
            return self._handle_regression(version)

        # æ›´æ–°æœ€ä½³ç‰ˆæœ¬
        if speedup_vs_baseline > self._get_best_speedup():
            self.state.best_version_id = version_id
            print(f"âœ… New best version: {version_id}")

        # æ£€æŸ¥æ”¶æ•›
        if speedup_vs_previous < (1 + self.CONVERGENCE_THRESHOLD):
            print(f"ğŸ“Š Convergence detected (improvement < {self.CONVERGENCE_THRESHOLD*100}%)")
            self.state.converged = True
            self.state.convergence_reason = f"Diminishing returns ({speedup_vs_previous:.3f}x)"

        return True

    def _try_next_strategy(
        self,
        strategies: List,
        code: str
    ) -> bool:
        """å°è¯•ä¸‹ä¸€ä¸ªç­–ç•¥"""
        if not strategies:
            return False
        # ç®€åŒ–å¤„ç†ï¼šç›´æ¥è¿”å›å¤±è´¥ï¼Œè®©ä¸»å¾ªç¯å¤„ç†
        return False

    def _handle_regression(self, version: OptimizationVersion) -> bool:
        """å¤„ç†æ€§èƒ½ä¸‹é™"""
        # æ ‡è®°ä¸ºå¤±è´¥ç‰ˆæœ¬
        version.build_success = False

        # åœ¨äº¤äº’æ¨¡å¼ä¸‹è¯¢é—®ç”¨æˆ·
        if self.mode == "interactive":
            response = input("Continue with next strategy? [y/n]: ")
            if response.lower() != 'y':
                self.state.converged = True
                self.state.convergence_reason = "User stopped after regression"
                return False

        return True

    def _ask_user_confirmation(self, strategy) -> bool:
        """äº¤äº’æ¨¡å¼ä¸‹è¯¢é—®ç”¨æˆ·ç¡®è®¤"""
        print(f"\n{'='*40}")
        print("Strategy Application Confirmation")
        print(f"{'='*40}")
        print(f"Strategy: {strategy.name}")
        print(f"Description: {strategy.description}")
        print(f"Expected speedup: {strategy.expected_speedup}x")
        print(f"Complexity: {strategy.complexity}")
        print(f"Prerequisites: {', '.join(strategy.prerequisites)}")
        print()

        response = input("Apply this strategy? [y/n/skip]: ").lower()
        return response == 'y'

    def _build(self, source: str, output: str) -> bool:
        """ç¼–è¯‘ CUDA ä»£ç """
        # è§£æåŸå§‹æ„å»ºå‘½ä»¤å¹¶æ›¿æ¢è¾“å…¥è¾“å‡º
        cmd = self.build_command.replace("{source}", source).replace("{output}", output)

        try:
            result = subprocess.run(
                cmd.split(),
                capture_output=True,
                text=True,
                timeout=60
            )
            return result.returncode == 0
        except Exception as e:
            print(f"Build error: {e}")
            return False

    def _get_best_code(self) -> str:
        """è·å–å½“å‰æœ€ä½³ç‰ˆæœ¬çš„ä»£ç """
        if self.state.best_version_id == "baseline":
            return self.state.baseline_code

        for v in self.state.versions:
            if v.version_id == self.state.best_version_id:
                with open(v.code_path, 'r') as f:
                    return f.read()

        return self.state.baseline_code

    def _get_best_metrics(self) -> Dict[str, float]:
        """è·å–å½“å‰æœ€ä½³ç‰ˆæœ¬çš„æŒ‡æ ‡"""
        if self.state.best_version_id == "baseline":
            return self.state.baseline_metrics

        for v in self.state.versions:
            if v.version_id == self.state.best_version_id:
                return v.metrics

        return self.state.baseline_metrics

    def _get_best_speedup(self) -> float:
        """è·å–å½“å‰æœ€ä½³åŠ é€Ÿæ¯”"""
        if not self.state.versions:
            return 1.0

        best = max(v.speedup_vs_baseline for v in self.state.versions)
        return best

    def _calculate_speedup(
        self,
        new_metrics: Dict[str, float],
        old_metrics: Dict[str, float]
    ) -> float:
        """è®¡ç®—åŠ é€Ÿæ¯” - ä»¥ GPU æ‰§è¡Œæ—¶é—´ä¸ºä¸»è¦æŒ‡æ ‡"""
        # ä¼˜å…ˆä½¿ç”¨ gpu_time (kernel æ‰§è¡Œæ—¶é—´ï¼Œå•ä½çº³ç§’)
        new_time = new_metrics.get('gpu_time', 0)
        old_time = old_metrics.get('gpu_time', 0)

        if new_time > 0 and old_time > 0:
            # åŠ é€Ÿæ¯” = æ—§æ—¶é—´ / æ–°æ—¶é—´ (æ—¶é—´è¶ŠçŸ­è¶Šå¥½)
            return old_time / new_time

        # å›é€€åˆ° sm_busy ä½œä¸ºæ€§èƒ½æŒ‡æ ‡
        new_perf = new_metrics.get('sm_busy', 0)
        old_perf = old_metrics.get('sm_busy', 0)

        if old_perf == 0:
            return 1.0

        return new_perf / old_perf

    def _format_time(self, nanoseconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´ä¸ºäººç±»å¯è¯»æ ¼å¼"""
        if nanoseconds == 0:
            return "N/A"
        if nanoseconds >= 1e9:
            return f"{nanoseconds / 1e9:.2f}s"
        elif nanoseconds >= 1e6:
            return f"{nanoseconds / 1e6:.2f}ms"
        elif nanoseconds >= 1e3:
            return f"{nanoseconds / 1e3:.2f}Î¼s"
        else:
            return f"{nanoseconds:.2f}ns"

    def _generate_strategy_params(self, strategy_name: str) -> Dict:
        """ç”Ÿæˆç­–ç•¥å‚æ•°"""
        defaults = {
            "block_tiling": {"bm": 32, "bn": 32, "bk": 8},
            "smem_padding": {"pad": 1},
            "vectorized_load": {},
            "loop_unrolling": {"unroll_factor": 4},
            "register_opt": {"max_threads": 256, "min_blocks": 2},
            "warp_primitives": {},
            "double_buffering": {"bm": 32, "bn": 32, "bk": 8},
            "grid_stride": {}
        }

        return defaults.get(strategy_name, {})

    def _generate_report(self) -> Dict:
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        report_path = self.work_dir / "optimization_report.md"

        # ç”Ÿæˆ Markdown æŠ¥å‘Š
        report_lines = [
            "# NCU CUDA è‡ªåŠ¨ä¼˜åŒ–æŠ¥å‘Š (v2)",
            "",
            f"**ä¼˜åŒ–æ—¶é—´**: {datetime.now().isoformat()}",
            f"**æºæ–‡ä»¶**: {self.source_file}",
            f"**ä¼˜åŒ–æ¨¡å¼**: {self.mode}",
            f"**è¿­ä»£æ¬¡æ•°**: {self.state.current_iteration}/{self.MAX_ITERATIONS}",
            "",
            "## ä¼˜åŒ–æ¦‚è§ˆ",
            "",
            f"- **åˆå§‹æ‰§è¡Œæ—¶é—´**: {self._format_time(self.state.baseline_metrics.get('gpu_time', 0))}",
            f"- **åˆå§‹ SM Busy**: {self.state.baseline_metrics.get('sm_busy', 0):.1f}%",
            f"- **åˆå§‹ Memory Throughput**: {self.state.baseline_metrics.get('memory_throughput', 0):.1f}%",
        ]

        if self.state.versions:
            best_metrics = self._get_best_metrics()
            best_speedup = self._get_best_speedup()
            report_lines.extend([
                f"- **æœ€ç»ˆæ‰§è¡Œæ—¶é—´**: {self._format_time(best_metrics.get('gpu_time', 0))}",
                f"- **æœ€ç»ˆ SM Busy**: {best_metrics.get('sm_busy', 0):.1f}%",
                f"- **æ€»åŠ é€Ÿæ¯”**: {best_speedup:.2f}x (ä»¥æ‰§è¡Œæ—¶é—´ä¸ºå‡†)",
                f"- **æœ€ä½³ç‰ˆæœ¬**: {self.state.best_version_id}",
                f"- **æ”¶æ•›çŠ¶æ€**: {'å·²æ”¶æ•›' if self.state.converged else 'æœªæ”¶æ•›'}",
            ])

            if self.state.convergence_reason:
                report_lines.append(f"- **æ”¶æ•›åŸå› **: {self.state.convergence_reason}")

        report_lines.extend([
            "",
            "## ä¼˜åŒ–å†ç¨‹",
            "",
            "| ç‰ˆæœ¬ | ç­–ç•¥ | æ‰§è¡Œæ—¶é—´ | SM Busy | ç›¸å¯¹Baseline | ç›¸å¯¹ä¸Šä¸€è½® | çŠ¶æ€ |",
            "|------|------|----------|---------|--------------|------------|------|",
        ])

        # Baseline
        baseline_sm = self.state.baseline_metrics.get('sm_busy', 0)
        baseline_time = self.state.baseline_metrics.get('gpu_time', 0)
        report_lines.append(
            f"| baseline | - | {self._format_time(baseline_time)} | {baseline_sm:.1f}% | 1.00x | - | âœ… |"
        )

        # æ¯ä¸ªç‰ˆæœ¬
        for v in self.state.versions:
            sm = v.metrics.get('sm_busy', 0)
            time = v.metrics.get('gpu_time', 0)
            status = "âœ…" if v.build_success else "âŒ"
            report_lines.append(
                f"| {v.version_id} | {v.strategy_name} | {self._format_time(time)} | {sm:.1f}% | "
                f"{v.speedup_vs_baseline:.2f}x | {v.speedup_vs_previous:.2f}x | {status} |"
            )

        report_lines.extend([
            "",
            "## è¯¦ç»†åˆ†æ",
            "",
        ])

        for v in self.state.versions:
            report_lines.extend([
                f"### {v.version_id}: {v.strategy_name}",
                "",
                f"- **ç­–ç•¥æè¿°**: {v.strategy_description}",
                f"- **ç›¸å¯¹Baselineæå‡**: {v.speedup_vs_baseline:.2f}x",
                f"- **ç›¸å¯¹ä¸Šä¸€è½®æå‡**: {v.speedup_vs_previous:.2f}x",
                "",
                "**å…³é”®æŒ‡æ ‡**:",
                "",
            ])

            for key, value in v.metrics.items():
                if isinstance(value, float):
                    report_lines.append(f"- {key}: {value:.2f}")

            report_lines.append("")

        # ä¿å­˜æŠ¥å‘Š
        report_content = '\n'.join(report_lines)
        with open(report_path, 'w') as f:
            f.write(report_content)

        print(f"\n{'='*60}")
        print("Optimization Complete!")
        print(f"{'='*60}")
        print(f"Report saved to: {report_path}")

        # ä¿å­˜æœ€ç»ˆæœ€ä½³ä»£ç 
        if self.state.best_version_id != "baseline":
            best_code = self._get_best_code()
            best_code_path = self.work_dir / "best_optimized.cu"
            with open(best_code_path, 'w') as f:
                f.write(best_code)
            print(f"Best code saved to: {best_code_path}")

        # è¿”å›ç»“æœå­—å…¸
        return {
            "success": True,
            "work_dir": str(self.work_dir),
            "report_path": str(report_path),
            "best_version": self.state.best_version_id,
            "best_speedup": self._get_best_speedup(),
            "iterations": self.state.current_iteration,
            "converged": self.state.converged,
            "versions": [asdict(v) for v in self.state.versions]
        }


def main():
    parser = argparse.ArgumentParser(
        description="NCU CUDA Optimizer v2 - Analysis & Optimization"
    )

    # ä¸»è¦å‚æ•°
    parser.add_argument(
        "source",
        nargs="?",
        help="CUDA source file to optimize/analyze"
    )

    # æ¨¡å¼é€‰æ‹©
    parser.add_argument(
        "--mode",
        choices=["auto", "interactive", "analyze"],
        default="auto",
        help=("Mode: auto=å…¨è‡ªåŠ¨ä¼˜åŒ–, interactive=äº¤äº’å¼ä¼˜åŒ–, "
              "analyze=åªåˆ†æä¸ä¼˜åŒ– (default: auto)")
    )

    # ä»æŠ¥å‘Šå¯¼å…¥ (v1 åŠŸèƒ½)
    parser.add_argument(
        "--import-report",
        metavar="REPORT",
        help="ä»å·²æœ‰çš„ .ncu-rep æ–‡ä»¶å¯¼å…¥åˆ†æ (åˆ†ææ¨¡å¼)"
    )

    # ç¼–è¯‘ç›¸å…³
    parser.add_argument(
        "--build",
        default="nvcc -O3 {source} -o {output}",
        help="Build command template"
    )

    # ä¿å­˜é€‰é¡¹
    parser.add_argument(
        "--no-save",
        action="store_true",
        help="ä¸ä¿å­˜æŠ¥å‘Šåˆ°é¡¹ç›®ç›®å½• (analyze æ¨¡å¼)"
    )

    # å…¶ä»–å‚æ•°
    parser.add_argument(
        "--ncu-path",
        default="ncu",
        help="Path to ncu executable"
    )
    parser.add_argument(
        "--max-iter",
        type=int,
        default=5,
        help="Maximum optimization iterations"
    )
    parser.add_argument(
        "--threshold",
        type=float,
        default=0.03,
        help="Convergence threshold"
    )

    args = parser.parse_args()

    # å¤„ç†å¯¼å…¥æŠ¥å‘Šæ¨¡å¼
    if args.import_report:
        # åˆ›å»ºä¸´æ—¶ optimizer (ä¸éœ€è¦ source file)
        profiler = NCUProfiler(args.ncu_path)
        success, metrics = profiler.profile_from_report(args.import_report)

        if success:
            library = CUDAStrategyLibrary()
            bottleneck = library.diagnose_bottleneck(metrics)
            recommendations = library.get_strategies_for_bottleneck(
                bottleneck, metrics
            )

            # æ‰“å°æŒ‡æ ‡æ‘˜è¦
            profiler.print_metrics_summary(metrics)

            print(f"\n{'='*60}")
            print("NCU Analysis Report (Imported)")
            print(f"{'='*60}")
            print(f"\nğŸ“Š Bottleneck: {bottleneck.value}")
            print(f"â±ï¸  GPU Time: {metrics.get('gpu_time', 'N/A')} Î¼s")
            print(f"\nğŸ’¡ Recommendations:")
            for i, r in enumerate(recommendations[:3], 1):
                print(f"  {i}. {r.name} ({r.expected_speedup}x)")

            sys.exit(0)
        else:
            print("âŒ Failed to import report")
            sys.exit(1)

    # æ£€æŸ¥ source file
    if not args.source:
        parser.error("source file is required (unless using --import-report)")

    # åˆ›å»º optimizer
    optimizer = CUDAOptimizer(
        source_file=args.source,
        build_command=args.build,
        mode=args.mode if args.mode in ["auto", "interactive"] else "auto",
        ncu_path=args.ncu_path
    )

    # è¦†ç›–é»˜è®¤å‚æ•°
    CUDAOptimizer.MAX_ITERATIONS = args.max_iter
    CUDAOptimizer.CONVERGENCE_THRESHOLD = args.threshold

    # æ‰§è¡Œå¯¹åº”æ¨¡å¼
    if args.mode == "analyze":
        # åˆ†ææ¨¡å¼ (v1 åŠŸèƒ½)
        result = optimizer.analyze_only(save_to_project=not args.no_save)
        if result["success"]:
            print("\nâœ… Analysis completed!")
            print(f"ğŸ“Š Bottleneck: {result['bottleneck']}")
            print(f"ğŸ’¡ Top recommendation: {result['recommendations'][0] if result['recommendations'] else 'N/A'}")
            sys.exit(0)
        else:
            print(f"\nâŒ Analysis failed: {result.get('error')}")
            sys.exit(1)
    else:
        # ä¼˜åŒ–æ¨¡å¼ (v2 åŠŸèƒ½)
        result = optimizer.run()
        if result["success"]:
            print("\nâœ… Optimization completed successfully!")
            sys.exit(0)
        else:
            print(f"\nâŒ Optimization failed: {result.get('error')}")
            sys.exit(1)


if __name__ == "__main__":
    main()
